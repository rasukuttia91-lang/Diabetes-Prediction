# -*- coding: utf-8 -*-
"""Project 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hQY3yQ_hs9KZJ-7nk1dBN0k3JRv_Y43m

Machine Learning Foundations Capstone Project: Diabetes Prediction

Course: AI Programmer / Machine Learning Foundations

Model Goal: To build a Classification Model (Logistic Regression) that can predict whether a patient will test positive for diabetes based on diagnostic measurements.

Part: 1 Data Acquisition and Exploratory Data Analysis (EDA)
"""

# Setup and Loading

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split as tts
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_curve, roc_auc_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score
#load the data

p2 = pd.read_csv("/content/Indian_Diabetes_Dataset_50K_MissingValues.csv")  # p2 = Project 2

# Inspect Data Structure

print("Display thr first 5 rows:\n", p2.head(5))

p2.info()
print("Display the number of rows and columns:\n", p2.shape)

# Descriptive Stats

print("Data Describe: \n",p2.describe())

#  Analyze Target Balance

print("Data Outcome:\n", p2["Outcome"].value_counts())

# Visualize Distributions

# Histograms plot for Glucose

plt.figure(figsize = (10, 5))
sns.histplot(p2['Glucose'], kde = True, color = 'skyblue', bins = 30)
plt.title('Distribution of Glucose Levels')
plt.xlabel('Glucose')
plt.ylabel('Frequency')
plt.show()

# Histograms plot for BMI

plt.figure(figsize = (10, 5))
sns.histplot(p2['BMI'], kde = True, color = 'salmon', bins = 30)
plt.title('Distribution of BMI')
plt.xlabel('BMI')
plt.ylabel('Frequency')
plt.show()

# count plot for the Outcome variable

plt.figure(figsize=(14, 8))
sns.countplot(x = 'Outcome', data = p2, palette = 'pastel', hue = "BMI", legend = False )
plt.title('Distribution of Diabetes Outcome')
plt.xlabel('Outcome (0 = No Diabetes, 1 = Diabetes)')
plt.ylabel('Count')
plt.xticks([0, 1], ['No Diabetes', 'Diabetes'])
plt.show()

# Handling Missing Data
# Identify Columns Glucose, BloodPressure, SkinThickness, Insulin, and BMI

print("Identify Columns:\n", p2.isnull().sum())

"""Part: 2 Data Preprocessing and Feature Engineering"""

# Imputation

# Correcting fillna for Glucose to impute NaNs with the median
p2["Glucose"] = p2["Glucose"].fillna(p2["Glucose"].median())
p2["BloodPressure"] = p2["BloodPressure"].fillna(p2["BloodPressure"].median())
p2["SkinThickness"] = p2["SkinThickness"].fillna(p2["SkinThickness"].median())
p2["Insulin"] = p2["Insulin"].fillna(p2["Insulin"].median())
p2["BMI"] = p2["BMI"].fillna(p2["BMI"].median())

# After Handling Missing Data

print("After Handling Missing Data:\n", p2.isnull().sum())

print("After Handling Missing Data:\n", p2.describe())

# Define X and y: Separate the features (X) from the target variable (y)

x = p2.drop("Outcome", axis = 1)
y = p2["Outcome"]

# Train-Test Split: Split the data into 70% for training and 30% for testing

x_train, x_test, y_train, y_test = tts(x, y, test_size = 0.3, random_state = 53)

#	Feature Scaling (Standardization)

scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)

"""Part 3: Model Training and Evaluation

Train the Classification Model
"""

# Train the Classification Model

model = LogisticRegression(solver = "liblinear", max_iter = 10000, random_state = 53)
model.fit(x_train_scaled, y_train)

# Make Predictions

y_pred = model.predict(x_test_scaled)

# Predict probability of buying
probs = model.predict_proba(x_test_scaled)[:, 1]
print("Probabilities:\n", probs)
# Predict Yes/No (1/0)
y_preds = model.predict(x_test_scaled)
print("Prediction:\n", y_preds)

from sklearn.metrics import classification_report

# Evaluate Performance

cm = confusion_matrix(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
rec = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
print("Confusion Matrix:\n", cm)
print("Accuracy:\n", acc)
print("Precision:\n", prec)
print("Recall:\n", rec)
print("F1 Score:\n", f1)
print("Classification Report:\n", classification_report(y_test, y_pred))

#ROC and AUC

# Compute ROC values

fpr, tpr, thresholds = roc_curve(y_test, probs)
auc = roc_auc_score(y_test, probs)
print("AUC Score:\n", auc)

# Plot ROC

plt.plot(fpr, tpr, label = f"AUC = {auc: 2f}", color = "r")
plt.plot([0,1],[0,1], linestyle = "-.", color = "b",) #random line
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate(Recall)")
plt.title("ROC Curve")
plt.legend()
print("Plot ROC:\n")
plt.show()